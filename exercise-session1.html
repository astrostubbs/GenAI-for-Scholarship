<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Session 1 Exercises — Generative AI for Scholarship</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<header>
    <div class="logos">
        <img src="HDSI.png" alt="Harvard Data Science Initiative">
        <img src="FAS.png" alt="Harvard Faculty of Arts and Sciences">
    </div>
    <h1>Generative AI for Scholarship</h1>
    <div class="sponsors">Harvard Data Science Initiative (HDSI) & Faculty of Arts and Sciences (FAS)</div>
</header>

<nav>
    <a href="index.html">Home</a>
    <a href="session1-foundation.html">The Basics</a>
    <a href="session2-coder.html">The AI-Empowered Coder</a>
    <a href="session3-power-user.html">Claude Code CLI</a>
    <a href="site-map.html">Site Map</a>
    <a href="https://datascience.harvard.edu/education/generative-ai-for-graduate-students-and-postdocs/" target="_blank">Other GAI Sessions</a>
</nav>

<h2>Session 1 Exercises</h2>

<p>
    These hands-on exercises will help you practice using Google's AI tools effectively.
    Make sure you're signed in with your Harvard-affiliated Google account
    (e.g., <code>yourname@g.harvard.edu</code>).
</p>

<h2>Exercise 1: Using Gemini for Meal Planning</h2>

<p>
    In this exercise, you'll practice crafting effective prompts to get useful,
    practical suggestions from Gemini.
</p>

<h3>Step 1: Open Gemini</h3>

<ol>
    <li>Go to <a href="https://gemini.google.com" target="_blank">gemini.google.com</a> (or access via the Google apps menu)</li>
    <li>Make sure you're signed in with your Harvard-affiliated account</li>
</ol>

<h3>Step 2: Try this basic prompt</h3>

<p>Copy and paste this prompt into Gemini:</p>

<pre><code>I have these ingredients in my fridge: milk, eggs, yoghurt, carrots, spring onions, bell pepper, cheese, leftover rice.

Can you suggest 3 meal ideas I could make with these ingredients?</code></pre>

<p>
    <strong>Observe:</strong> What kind of suggestions does Gemini provide? Are they practical?
    Do they use all the ingredients or just some of them?
</p>

<p>
    We'll explore ways to improve this prompt during the workshop discussion.
</p>

<h3>Step 3: Generate a scientific image</h3>

<p>
    Gemini can also generate images from text descriptions. Try creating a
    scientific illustration by entering one of these prompts (or make up your own):
</p>

<pre><code>Create a diagram showing the layers of Earth's atmosphere,
labeled with altitude, temperature profile, and key features
(ozone layer, tropopause, etc.).</code></pre>

<pre><code>Draw a schematic of the cosmic distance ladder, showing the
sequence of methods used to measure distances at increasing
scales: parallax, Cepheid variables, Type Ia supernovae,
and the Hubble flow.</code></pre>

<pre><code>Generate an illustration of CRISPR-Cas9 editing a strand of DNA,
showing the guide RNA, Cas9 protein, and the target sequence.</code></pre>

<pre><code>Create a visualization of the water cycle in a changing climate,
showing evaporation, cloud formation, precipitation, runoff,
and groundwater recharge with arrows indicating energy flows.</code></pre>

<p>
    <strong>Observe:</strong> How accurate is the scientific content? Are labels correct?
    Would you trust this in a presentation without checking it? This is a good
    opportunity to think critically about AI-generated visual content.
</p>

<h2>Exercise 2: Interactive Physics Simulator with Canvas</h2>

<p>
    In this exercise, you'll use Gemini's <strong>Canvas</strong> tool to generate an interactive
    physics simulation directly in your browser. This demonstrates how AI can create functional,
    interactive applications from a simple natural language description.
</p>

<h3>Step 1: Invoke Canvas</h3>

<p>
    In Gemini, select <strong>Canvas</strong> from the tools menu (the dropdown near the prompt box).
</p>

<h3>Step 2: Enter this prompt</h3>

<p>Copy and paste this prompt:</p>

<pre><code>Make me an interactive simulator of a damped simple harmonic oscillator. Allow me to set parameters with sliders.</code></pre>

<p>
    <strong>Observe:</strong> Canvas should generate an interactive web application with sliders
    for parameters like mass, spring constant, damping coefficient, and initial displacement.
    You should be able to adjust them in real time and see the oscillator's behavior change.
</p>

<p>
    <strong>Discussion:</strong> Think about what just happened — you described a physics concept
    in plain English and got a working interactive simulation. How might this be useful for
    teaching, exploring parameter spaces, or building quick prototypes?
</p>

<h2>Exercise 3: Using NotebookLM for Document Analysis</h2>

<p>
    NotebookLM is Google's AI-powered research assistant designed specifically for
    working with your own documents. Unlike Gemini, which can answer general questions,
    NotebookLM focuses on analyzing and synthesizing content from files you upload.
</p>

<h3>Step 1: Open NotebookLM</h3>

<ol>
    <li>Go to <a href="https://google.com" target="_blank">google.com</a> and make sure you're signed in with your Harvard-affiliated account</li>
    <li>Click the Google apps menu (the 3×3 grid of dots) in the upper right corner</li>
    <li>Look for <strong>NotebookLM</strong> in the menu (you may need to scroll or search)</li>
    <li>Click to open NotebookLM</li>
</ol>

<p>
    Alternatively, you can go directly to <a href="https://notebooklm.google.com" target="_blank">notebooklm.google.com</a>
</p>

<h3>Step 2: Explore NotebookLM</h3>

<p>
    In the workshop, we'll demonstrate how to upload documents and use NotebookLM to
    analyze research papers, compare sources, and generate summaries.
</p>

<h3>Step 3: Try the Grant Proposal Exercise</h3>

<p>
    Now we'll use NotebookLM's document comparison capabilities for a real research task:
    checking a draft grant proposal against NSF guidelines.
</p>

<p>
    <strong>Materials for this exercise:</strong>
</p>

<ul class="resources">
    <li><a href="draft_proposal.pdf" download>Draft Grant Proposal</a> <span class="desc">A sample NSF DMREF proposal (intentionally contains errors)</span></li>
    <li><a href="NSF 25-508_ Designing_Materials.pdf" download>NSF DMREF Call</a> <span class="desc">The official NSF program solicitation</span></li>
    <li><a href="nsf23_1.pdf" download>NSF Proposal Guide</a> <span class="desc">General NSF proposal requirements</span></li>
</ul>

<p>
    <strong>Step-by-step instructions:</strong>
</p>

<ol>
    <li><strong>Create a new notebook</strong>: In NotebookLM, click "New notebook" or the "+" button to start fresh.</li>

    <li><strong>Upload the three PDF documents</strong>: Click "Add source" or the "+" button and upload:
        <ul style="margin-top: 0.5rem;">
            <li>draft_proposal.pdf</li>
            <li>NSF 25-508_ Designing_Materials.pdf</li>
            <li>nsf23_1.pdf</li>
        </ul>
        Wait for all three to finish processing (you'll see checkmarks when ready).
    </li>

    <li><strong>Ask NotebookLM to review the proposal</strong>: Copy and paste this prompt into the chat:</li>
</ol>

<pre><code>I need you to compare the draft proposal to the requirements listed
in the other two PDF files. Act as a fastidious grant administrator
and give me a numbered listing of things that need modification.</code></pre>

<p>
    <strong>Observe:</strong> Notice how NotebookLM cites specific pages and sections
    from the source documents when it identifies issues. This source-grounded approach
    makes it particularly valuable for document analysis tasks. You should see it identify
    multiple compliance problems with specific references to the NSF guidelines.
</p>

<h2>Discussion: Ethics of AI Use in Research</h2>

<p>
    Before moving to the next exercise, let's pause to discuss the ethical considerations
    and social norms around using AI tools in academic work.
</p>

<p>
    <strong>Questions to consider:</strong>
</p>

<ul class="resources">
    <li><strong>Attribution and disclosure:</strong> If you use NotebookLM to review your grant proposal,
        should you disclose this to the funding agency? What if it helps you write sections of the proposal?
        Where is the line between "tool" and "co-author"?</li>

    <li><strong>Lack of established norms:</strong> Unlike citation practices or authorship guidelines,
        which have evolved over decades, social norms for AI use in research are still emerging.
        Different journals, funding agencies, and institutions have different policies—or no policy at all.
        How do you navigate this uncertainty?</li>

    <li><strong>Competitive advantage vs. fairness:</strong> If some researchers use AI tools and others don't,
        does this create an unfair advantage? Should AI assistance be disclosed to ensure transparency?</li>

    <li><strong>Responsibility and verification:</strong> When AI identifies errors or suggests improvements,
        you are still responsible for the final work. How do you verify AI-generated insights?
        What happens if AI misses something important or provides incorrect information?</li>

    <li><strong>Clarity within your research group:</strong> It's essential to establish shared expectations
        between participants and advisors, PIs and postdocs, about appropriate AI use. These conversations should
        be explicit and ongoing. Different sub-fields are developing their own norms—some more permissive,
        others more restrictive. You need to stay abreast of evolving practices in your specific field and
        discuss them openly within your research group.</li>
</ul>

<div class="disclaimer" style="background: #fff3cd; border-left: 4px solid #ff9800; text-align: center; padding: 1.5rem; margin: 2rem 0;">
    <h3 style="margin-top: 0; color: #ff9800; font-size: 1.5rem;">DISCLOSE. DISCLOSE. DISCLOSE.</h3>
    <p style="margin-bottom: 0;">
        When in doubt, err on the side of transparency. Disclose your use of AI tools to
        collaborators, advisors, journals, and funding agencies. Transparency protects you
        and helps establish community norms.
    </p>
</div>

<p>
    <strong>Key takeaway:</strong> As AI tools become more powerful and ubiquitous, the research community
    needs to develop clear ethical guidelines and social norms. Until those norms are established,
    transparency, disclosure, and critical thinking about appropriate use are essential.
</p>

<h2>Discussion: Validation, Verification, and Responsibility</h2>

<p>
    A critical complement to the ethics discussion above:
</p>

<div class="disclaimer" style="background: #fff3cd; border-left: 4px solid #ff9800; text-align: center; padding: 1.5rem; margin: 2rem 0;">
    <h3 style="margin-top: 0; color: #ff9800; font-size: 1.5rem;">VALIDATE. VERIFY. CHECK!</h3>
    <p style="margin-bottom: 0;">
        <strong>You are responsible for any and all generative AI outputs you use</strong> — in papers,
        proposals, code, presentations, or any other work product. AI is a tool, not an authority.
    </p>
</div>

<ul class="resources">
    <li><strong>Always validate AI output:</strong> AI can produce plausible-sounding but incorrect
        results (hallucinations), miss important nuances, or reflect biases in its training data.
        Never use AI-generated content without independent verification.</li>
    <li><strong>Treat AI as a first draft:</strong> Think of AI output as a starting point that
        requires expert review, not as a finished product ready for use.</li>
    <li><strong>Check facts, citations, and calculations:</strong> AI frequently generates
        plausible-looking citations that don't exist, and can make subtle errors in calculations
        or reasoning. Verify everything.</li>
    <li><strong>Domain expertise matters more than ever:</strong> AI tools are most useful in the
        hands of someone who can recognize when the output is wrong. Your expertise is the
        quality control layer.</li>
</ul>

<h2>Exercise 4: Using NotebookLM for Literature Review</h2>

<p>
    One of NotebookLM's most powerful applications is synthesizing information across
    multiple research papers. In this exercise, you'll see how it can help with
    literature review and research synthesis.
</p>

<p>
    <strong>Step-by-step instructions:</strong>
</p>

<ol>
    <li><strong>Create a new notebook</strong>: Start a fresh notebook for this exercise.</li>

    <li><strong>Upload science papers</strong>: Upload 3-5 research papers from your field
        (PDF format). For this demonstration, instructors can use any set of related papers
        on a common topic (e.g., climate modeling, materials science, machine learning).</li>

    <li><strong>Ask for a summary</strong>: Try prompts like:
        <pre><code>Summarize the main findings of these papers.

What are the common themes across these research articles?

How do the methodologies differ across these studies?

What gaps in the research do these papers reveal?</code></pre>
    </li>

    <li><strong>Follow-up questions</strong>: After the initial summary, ask more specific questions:
        <pre><code>Which paper has the most comprehensive methodology?

What are the key disagreements or contradictions between authors?

Suggest directions for future research based on these papers.</code></pre>
    </li>
</ol>

<p>
    <strong>Observe:</strong> NotebookLM will synthesize information across all uploaded
    papers, citing specific sources for each claim. This is invaluable for literature
    reviews, where you need to track which paper said what.
</p>

<p>
    <strong>Bonus:</strong> Try the "Generate Audio Overview" feature (if available) to
    create a podcast-style discussion of the research papers!
</p>

<h2>Exercise 5: Data Browsing with Gemini</h2>

<p>
    In this exercise, you'll upload a spreadsheet to Gemini and see how it can
    browse and interpret tabular data. This demonstrates how AI can quickly
    identify patterns and trends in datasets.
</p>

<h3>Step 1: Download the data file</h3>

<p style="text-align: center; margin: 1rem 0;">
    <a href="fake_data.xlsx" download
       style="display: inline-block; background: #A51C30; color: white; padding: 0.75rem 1.5rem; text-decoration: none; border-radius: 4px; font-weight: bold;">
        Download fake_data.xlsx
    </a>
</p>

<h3>Step 2: Upload to Gemini</h3>

<ol>
    <li>Go to <a href="https://gemini.google.com" target="_blank">gemini.google.com</a></li>
    <li>Click the <strong>+</strong> button (attach file) and upload <code>fake_data.xlsx</code></li>
</ol>

<h3>Step 3: Prompt Gemini to analyze the data</h3>

<p>Copy and paste this prompt:</p>

<pre><code>I have uploaded an Excel spreadsheet. The columns are date, temperature (F),
number of bees detected, and number of butterflies detected.
Tell me what we can learn from the data file.</code></pre>

<p>
    <strong>Observe:</strong> How does Gemini interpret the data? Does it identify
    seasonal patterns? Correlations between temperature and insect counts?
    Does it generate any visualizations? Try follow-up prompts to dig deeper
    into specific trends or ask it to create plots.
</p>

<h2>Exercise 6: Pre-Submission Paper Review</h2>

<p>
    In this exercise, you'll upload one of your own papers (a draft or a published paper)
    to Gemini and ask it for a constructive critique. Think of this as a <strong>first
    stage of self-review</strong> — like asking a knowledgeable colleague to read your
    draft and point out issues before you submit.
</p>

<div class="disclaimer" style="background: #d1ecf1; border-left: 4px solid #17a2b8;">
    <strong>Important:</strong> This is <strong>not</strong> a substitute for the formal
    peer review process. It's a way to catch obvious problems before reviewers see them.
    Remember to use your <strong>Harvard Google account</strong> so your paper is protected
    by Harvard's data security agreements.
</div>

<h3>Step 1: Upload your paper</h3>

<ol>
    <li>Go to <a href="https://gemini.google.com" target="_blank">gemini.google.com</a></li>
    <li>Click the <strong>+</strong> button and upload a PDF of one of your own papers</li>
</ol>

<h3>Step 2: Ask for a critique</h3>

<p>Copy and paste this prompt (or adapt it to your needs):</p>

<pre><code>I have uploaded one of my own papers. Please act as a thorough and
constructive colleague helping me review it before submission. Please:

1. Summarize what you understand to be the main contributions
2. Check whether the abstract accurately reflects the paper's content
3. Identify any gaps in the logic or argument
4. Flag places where claims are not well supported by the data
5. Point out unclear writing, jargon, or confusing figures
6. Check that all figures and tables are referenced in the text
7. Assess whether the abstract combined with the figure captions
   conveys the main message of the paper
8. Note any missing citations or incomplete references
9. Suggest specific improvements

Be constructive and specific. Cite section numbers, figure numbers,
or page numbers when making suggestions.</code></pre>

<p>
    <strong>Observe:</strong> How useful is the feedback? Does it catch real issues?
    Are there things it misses that a human reviewer would catch? Try follow-up
    prompts to dig deeper into specific sections.
</p>

<h2>Exercise 7: Creating a Gem</h2>

<p>
    <strong>Gems</strong> are custom AI assistants in Gemini with two kinds of persistence:
</p>

<ul class="resources">
    <li><strong>Persistent prompts:</strong> A Gem stores its instructions (the "system prompt")
        permanently, so you don't have to re-type or paste a long prompt every time you start
        a new conversation. The Gem always knows its role and how to behave.</li>
    <li><strong>Persistent context materials:</strong> You can upload reference documents
        (PDFs, style guides, journal guidelines, datasets) that the Gem always has access to.
        Every conversation with that Gem starts with those documents already loaded.</li>
</ul>

<p>
    This combination means you can build specialized tools that are ready to use
    immediately — no setup required each time. Gems can also be shared with
    colleagues in your Google Workspace, so an entire research group can use the
    same standardized assistant.
</p>

<h3>Step 1: Open the Gem Manager</h3>

<ol>
    <li>In Gemini, look for <strong>"Gem manager"</strong> in the left sidebar (or under a menu).</li>
    <li>Click <strong>"New Gem"</strong> or <strong>"Create Gem"</strong>.</li>
</ol>

<h3>Step 2: Create a "Pre-Submission Paper Reviewer" Gem</h3>

<p>
    Let's convert the paper review prompt from Exercise 6 into a reusable Gem.
</p>

<ol>
    <li><strong>Name it</strong>: "Pre-Submission Paper Reviewer"</li>

    <li><strong>Paste these instructions</strong> as the Gem's persistent prompt:
        <pre><code>When the user uploads a PDF of one of their papers, act as a thorough
and constructive colleague helping them review it before submission.

For each paper uploaded:
1. Summarize the main contributions
2. Check whether the abstract accurately reflects the paper's content
3. Identify any gaps in the logic or argument
4. Flag places where claims are not well supported by the data
5. Point out unclear writing, jargon, or confusing figures
6. Check that all figures and tables are referenced in the text
7. Assess whether the abstract combined with the figure captions
   conveys the main message of the paper
8. Note any missing citations or incomplete references
9. Suggest specific improvements

Be constructive and specific. Cite section numbers, figure numbers,
or page numbers when making suggestions.</code></pre>
    </li>

    <li><strong>Upload reference documents (optional)</strong>: If you have target journal
        guidelines or a style guide, upload them so the Gem always considers them.</li>

    <li><strong>Save</strong> the Gem.</li>
</ol>

<h3>Step 3: Test your Gem</h3>

<ol>
    <li>Open your new Gem from the Gem manager.</li>
    <li>Upload a PDF of one of your papers — notice that you don't need to paste
        any instructions. The Gem already knows what to do.</li>
    <li>Compare the results to what you got in Exercise 5. Is the output similar?</li>
</ol>

<p>
    <strong>Other Gem ideas for research:</strong>
</p>

<ul class="resources">
    <li><strong>Grant Writing Assistant</strong>: Persistent prompt checks proposals against uploaded funding agency guidelines</li>
    <li><strong>Literature Synthesizer</strong>: Summarizes papers in a consistent format you define</li>
    <li><strong>Methods Section Writer</strong>: Uploads your lab's style guide and helps document procedures</li>
    <li><strong>Course Teaching Assistant</strong>: Uploads the syllabus and textbook chapters so it can answer student questions grounded in course materials</li>
</ul>

<h2>Discussion</h2>

<p>
    In the workshop, we'll discuss what you observed and explore how to improve prompts
    to get more useful results. Think about:
</p>

<ul class="resources">
    <li>What worked well in Gemini's response?</li>
    <li>What could be improved?</li>
    <li>How might you refine the prompt to get better suggestions?</li>
    <li>How does this relate to using AI for research tasks?</li>
</ul>

<h2>Post-Session Survey</h2>

<p>
    Please take a moment to share your feedback — it helps us improve future sessions.
</p>

<p style="text-align: center; margin: 1.5rem 0;">
    <a href="https://bit.ly/4rlIBCt" target="_blank"
       style="display: inline-block; background: #A51C30; color: white; padding: 0.75rem 1.5rem; text-decoration: none; border-radius: 4px; font-weight: bold; font-size: 1.1rem;">
        Take the Post-Session Survey
    </a>
</p>

<footer>
    <p>
        &copy; 2026 President and Fellows of Harvard College.
        Licensed under
        <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
</footer>

<script data-goatcounter="https://genaiatfas.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
</body>
</html>
