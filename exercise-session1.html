<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Session 1 Exercises — Generative AI for Scholarship</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<header>
    <div class="logos">
        <img src="HDSI.png" alt="Harvard Data Science Initiative">
        <img src="FAS.png" alt="Harvard Faculty of Arts and Sciences">
    </div>
    <h1>Generative AI for Scholarship</h1>
    <div class="sponsors">Harvard Data Science Initiative (HDSI) & Faculty of Arts and Sciences (FAS)</div>
</header>

<nav>
    <a href="index.html">Home</a>
    <a href="session1-foundation.html">The Basics</a>
    <a href="session2-coder.html">The AI-Empowered Coder</a>
    <a href="session3-power-user.html">Claude Code CLI</a>
    <a href="site-map.html">Site Map</a>
    <a href="https://datascience.harvard.edu/education/generative-ai-for-graduate-students-and-postdocs/" target="_blank">Other GAI Sessions</a>
</nav>

<h2>Session 1 Exercises</h2>

<p>
    These hands-on exercises will help you practice using Google's AI tools effectively.
    Make sure you're signed in with your Harvard-affiliated Google account
    (e.g., <code>yourname@g.harvard.edu</code>).
</p>

<h2>Exercise 1: Using Gemini for Meal Planning</h2>

<p>
    In this exercise, you'll practice crafting effective prompts to get useful,
    practical suggestions from Gemini.
</p>

<h3>Step 1: Open Gemini</h3>

<ol>
    <li>Go to <a href="https://gemini.google.com" target="_blank">gemini.google.com</a> (or access via the Google apps menu)</li>
    <li>Make sure you're signed in with your Harvard-affiliated account</li>
</ol>

<h3>Step 2: Try this basic prompt</h3>

<p>Copy and paste this prompt into Gemini:</p>

<pre><code>I have these ingredients in my fridge: milk, eggs, yoghurt, carrots, spring onions, bell pepper, cheese, leftover rice.

Can you suggest 3 meal ideas I could make with these ingredients?</code></pre>

<p>
    <strong>Observe:</strong> What kind of suggestions does Gemini provide? Are they practical?
    Do they use all the ingredients or just some of them?
</p>

<p>
    We'll explore ways to improve this prompt during the class discussion.
</p>

<h2>Exercise 2: Using NotebookLM for Document Analysis</h2>

<p>
    NotebookLM is Google's AI-powered research assistant designed specifically for
    working with your own documents. Unlike Gemini, which can answer general questions,
    NotebookLM focuses on analyzing and synthesizing content from files you upload.
</p>

<h3>Step 1: Open NotebookLM</h3>

<ol>
    <li>Go to <a href="https://google.com" target="_blank">google.com</a> and make sure you're signed in with your Harvard-affiliated account</li>
    <li>Click the Google apps menu (the 3×3 grid of dots) in the upper right corner</li>
    <li>Look for <strong>NotebookLM</strong> in the menu (you may need to scroll or search)</li>
    <li>Click to open NotebookLM</li>
</ol>

<p>
    Alternatively, you can go directly to <a href="https://notebooklm.google.com" target="_blank">notebooklm.google.com</a>
</p>

<h3>Step 2: Explore NotebookLM</h3>

<p>
    In class, we'll demonstrate how to upload documents and use NotebookLM to
    analyze research papers, compare sources, and generate summaries.
</p>

<h3>Step 3: Try the Grant Proposal Exercise</h3>

<p>
    Now we'll use NotebookLM's document comparison capabilities for a real research task:
    checking a draft grant proposal against NSF guidelines.
</p>

<p>
    <strong>Materials for this exercise:</strong>
</p>

<ul class="resources">
    <li><a href="draft_proposal.pdf" download>Draft Grant Proposal</a> <span class="desc">A sample NSF DMREF proposal (intentionally contains errors)</span></li>
    <li><a href="NSF 25-508_ Designing_Materials.pdf" download>NSF DMREF Call</a> <span class="desc">The official NSF program solicitation</span></li>
    <li><a href="nsf23_1.pdf" download>NSF Proposal Guide</a> <span class="desc">General NSF proposal requirements</span></li>
</ul>

<p>
    <strong>Step-by-step instructions:</strong>
</p>

<ol>
    <li><strong>Create a new notebook</strong>: In NotebookLM, click "New notebook" or the "+" button to start fresh.</li>

    <li><strong>Upload the three PDF documents</strong>: Click "Add source" or the "+" button and upload:
        <ul style="margin-top: 0.5rem;">
            <li>draft_proposal.pdf</li>
            <li>NSF 25-508_ Designing_Materials.pdf</li>
            <li>nsf23_1.pdf</li>
        </ul>
        Wait for all three to finish processing (you'll see checkmarks when ready).
    </li>

    <li><strong>Ask NotebookLM to review the proposal</strong>: Copy and paste this prompt into the chat:</li>
</ol>

<pre><code>I need you to compare the draft proposal to the requirements listed
in the other two PDF files. Act as a fastidious grant administrator
and give me a numbered listing of things that need modification.</code></pre>

<p>
    <strong>Observe:</strong> Notice how NotebookLM cites specific pages and sections
    from the source documents when it identifies issues. This source-grounded approach
    makes it particularly valuable for document analysis tasks. You should see it identify
    multiple compliance problems with specific references to the NSF guidelines.
</p>

<h2>Discussion: Ethics of AI Use in Research</h2>

<p>
    Before moving to the next exercise, let's pause to discuss the ethical considerations
    and social norms around using AI tools in academic work.
</p>

<p>
    <strong>Questions to consider:</strong>
</p>

<ul class="resources">
    <li><strong>Attribution and disclosure:</strong> If you use NotebookLM to review your grant proposal,
        should you disclose this to the funding agency? What if it helps you write sections of the proposal?
        Where is the line between "tool" and "co-author"?</li>

    <li><strong>Lack of established norms:</strong> Unlike citation practices or authorship guidelines,
        which have evolved over decades, social norms for AI use in research are still emerging.
        Different journals, funding agencies, and institutions have different policies—or no policy at all.
        How do you navigate this uncertainty?</li>

    <li><strong>Competitive advantage vs. fairness:</strong> If some researchers use AI tools and others don't,
        does this create an unfair advantage? Should AI assistance be disclosed to ensure transparency?</li>

    <li><strong>Responsibility and verification:</strong> When AI identifies errors or suggests improvements,
        you are still responsible for the final work. How do you verify AI-generated insights?
        What happens if AI misses something important or provides incorrect information?</li>

    <li><strong>Clarity within your research group:</strong> It's essential to establish shared expectations
        between students and advisors, PIs and postdocs, about appropriate AI use. These conversations should
        be explicit and ongoing. Different sub-fields are developing their own norms—some more permissive,
        others more restrictive. You need to stay abreast of evolving practices in your specific field and
        discuss them openly within your research group.</li>
</ul>

<div class="disclaimer" style="background: #fff3cd; border-left: 4px solid #ff9800; text-align: center; padding: 1.5rem; margin: 2rem 0;">
    <h3 style="margin-top: 0; color: #ff9800; font-size: 1.5rem;">DISCLOSE. DISCLOSE. DISCLOSE.</h3>
    <p style="margin-bottom: 0;">
        When in doubt, err on the side of transparency. Disclose your use of AI tools to
        collaborators, advisors, journals, and funding agencies. Transparency protects you
        and helps establish community norms.
    </p>
</div>

<p>
    <strong>Key takeaway:</strong> As AI tools become more powerful and ubiquitous, the research community
    needs to develop clear ethical guidelines and social norms. Until those norms are established,
    transparency, disclosure, and critical thinking about appropriate use are essential.
</p>

<h2>Exercise 3: Using NotebookLM for Literature Review</h2>

<p>
    One of NotebookLM's most powerful applications is synthesizing information across
    multiple research papers. In this exercise, you'll see how it can help with
    literature review and research synthesis.
</p>

<p>
    <strong>Step-by-step instructions:</strong>
</p>

<ol>
    <li><strong>Create a new notebook</strong>: Start a fresh notebook for this exercise.</li>

    <li><strong>Upload science papers</strong>: Upload 3-5 research papers from your field
        (PDF format). For this demonstration, instructors can use any set of related papers
        on a common topic (e.g., climate modeling, materials science, machine learning).</li>

    <li><strong>Ask for a summary</strong>: Try prompts like:
        <pre><code>Summarize the main findings of these papers.

What are the common themes across these research articles?

How do the methodologies differ across these studies?

What gaps in the research do these papers reveal?</code></pre>
    </li>

    <li><strong>Follow-up questions</strong>: After the initial summary, ask more specific questions:
        <pre><code>Which paper has the most comprehensive methodology?

What are the key disagreements or contradictions between authors?

Suggest directions for future research based on these papers.</code></pre>
    </li>
</ol>

<p>
    <strong>Observe:</strong> NotebookLM will synthesize information across all uploaded
    papers, citing specific sources for each claim. This is invaluable for literature
    reviews, where you need to track which paper said what.
</p>

<p>
    <strong>Bonus:</strong> Try the "Generate Audio Overview" feature (if available) to
    create a podcast-style discussion of the research papers!
</p>

<h2>Exercise 4: Data Browsing with Gemini</h2>

<p>
    In this exercise, you'll upload a spreadsheet to Gemini and see how it can
    browse and interpret tabular data. This demonstrates how AI can quickly
    identify patterns and trends in datasets.
</p>

<h3>Step 1: Download the data file</h3>

<p style="text-align: center; margin: 1rem 0;">
    <a href="fake_data.xlsx" download
       style="display: inline-block; background: #A51C30; color: white; padding: 0.75rem 1.5rem; text-decoration: none; border-radius: 4px; font-weight: bold;">
        Download fake_data.xlsx
    </a>
</p>

<h3>Step 2: Upload to Gemini</h3>

<ol>
    <li>Go to <a href="https://gemini.google.com" target="_blank">gemini.google.com</a></li>
    <li>Click the <strong>+</strong> button (attach file) and upload <code>fake_data.xlsx</code></li>
</ol>

<h3>Step 3: Prompt Gemini to analyze the data</h3>

<p>Copy and paste this prompt:</p>

<pre><code>I have uploaded an Excel spreadsheet. The columns are date, temperature (F),
number of bees detected, and number of butterflies detected.
Tell me what we can learn from the data file.</code></pre>

<p>
    <strong>Observe:</strong> How does Gemini interpret the data? Does it identify
    seasonal patterns? Correlations between temperature and insect counts?
    Does it generate any visualizations? Try follow-up prompts to dig deeper
    into specific trends or ask it to create plots.
</p>

<h2>Exercise 5: Pre-Submission Paper Review</h2>

<p>
    In this exercise, you'll upload one of your own papers (a draft or a published paper)
    to Gemini and ask it for a constructive critique. Think of this as a <strong>first
    stage of self-review</strong> — like asking a knowledgeable colleague to read your
    draft and point out issues before you submit.
</p>

<div class="disclaimer" style="background: #d1ecf1; border-left: 4px solid #17a2b8;">
    <strong>Important:</strong> This is <strong>not</strong> a substitute for the formal
    peer review process. It's a way to catch obvious problems before reviewers see them.
    Remember to use your <strong>Harvard Google account</strong> so your paper is protected
    by Harvard's data security agreements.
</div>

<h3>Step 1: Upload your paper</h3>

<ol>
    <li>Go to <a href="https://gemini.google.com" target="_blank">gemini.google.com</a></li>
    <li>Click the <strong>+</strong> button and upload a PDF of one of your own papers</li>
</ol>

<h3>Step 2: Ask for a critique</h3>

<p>Copy and paste this prompt (or adapt it to your needs):</p>

<pre><code>I have uploaded one of my own papers. Please act as a thorough and
constructive colleague helping me review it before submission. Please:

1. Summarize what you understand to be the main contributions
2. Check whether the abstract accurately reflects the paper's content
3. Identify any gaps in the logic or argument
4. Flag places where claims are not well supported by the data
5. Point out unclear writing, jargon, or confusing figures
6. Check that all figures and tables are referenced in the text
7. Assess whether the abstract combined with the figure captions
   conveys the main message of the paper
8. Note any missing citations or incomplete references
9. Suggest specific improvements

Be constructive and specific. Cite section numbers, figure numbers,
or page numbers when making suggestions.</code></pre>

<p>
    <strong>Observe:</strong> How useful is the feedback? Does it catch real issues?
    Are there things it misses that a human reviewer would catch? Try follow-up
    prompts to dig deeper into specific sections.
</p>

<h3>Step 3 (Optional): Turn this into a reusable Gem</h3>

<p>
    If you find this useful, you can create a <strong>Gem</strong> — a custom AI
    assistant with a persistent prompt — so you don't have to paste the
    instructions every time.
</p>

<ol>
    <li><strong>Access Gems</strong>: In Gemini, look for the "Gem manager" option (usually
        in the left sidebar or under a menu).</li>
    <li><strong>Create a new Gem</strong>: Click "New Gem" or "Create Gem".</li>
    <li><strong>Paste the prompt above</strong> as the Gem's persistent instructions.</li>
    <li><strong>Name it</strong>: e.g., "Pre-Submission Paper Reviewer".</li>
    <li><strong>Upload reference documents (optional)</strong>: You can add target journal
        guidelines or style guides that the Gem should always consider.</li>
    <li><strong>Share if desired</strong>: Gems can be shared with colleagues in your
        Google Workspace, making it easy to standardize review workflows across
        a research group.</li>
</ol>

<p>
    <strong>Other Gem ideas for research:</strong>
</p>

<ul class="resources">
    <li><strong>Grant Writing Assistant</strong>: Helps structure proposals and checks for common requirements</li>
    <li><strong>Literature Synthesizer</strong>: Summarizes papers in a consistent format</li>
    <li><strong>Methods Section Writer</strong>: Helps document experimental procedures in proper style</li>
    <li><strong>Data Analysis Explainer</strong>: Interprets statistical results for non-specialists</li>
    <li><strong>Lab Protocol Checker</strong>: Reviews protocols for completeness and safety</li>
</ul>

<h2>Discussion</h2>

<p>
    In class, we'll discuss what you observed and explore how to improve prompts
    to get more useful results. Think about:
</p>

<ul class="resources">
    <li>What worked well in Gemini's response?</li>
    <li>What could be improved?</li>
    <li>How might you refine the prompt to get better suggestions?</li>
    <li>How does this relate to using AI for research tasks?</li>
</ul>

<footer>
    <p>
        &copy; 2026 President and Fellows of Harvard College.
        Licensed under
        <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
</footer>

<script data-goatcounter="https://genaiatfas.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
</body>
</html>
